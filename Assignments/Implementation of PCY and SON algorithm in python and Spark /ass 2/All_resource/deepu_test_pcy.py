import sysimport osimport itertoolsfrequent_item_list = []support = 0bucket_size = 0frq_sets_all=[]singleton_set={}def generate_hash_value(a,b,each_subset):     total = 0     #total = (each_subset[1]*b)+(each_subset[0]*a)     for i in range(len(each_subset)):         (x,y) = each_subset     total=int(x)*a+int(y)*b     return total % bucket_sizedef compute_hash(bit_map,hash_bucket,  input_file):    with open(input_file) as file:        for transaction in file:            list_transaction = transaction.strip().split(',')            list_transaction.sort()            subsets_k = itertools.combinations(list_transaction,2)            subset_k_list = list(subsets_k)            for each_subset in subset_k_list:                bucket_number = generate_hash_value(a,b,each_subset)                hash_bucket.setdefault(bucket_number, 0)                count = hash_bucket[bucket_number]                count = count + 1                hash_bucket[bucket_number] = count    for bucket_num, count in hash_bucket.iteritems():        if count >= support:            bit_map.insert(bucket_num, 1)        else:            bit_map.insert(bucket_num, 0)    return (bit_map,hash_bucket)    file.close()def compute_frequent_item_sets(input_file, candidate_item_sets):    #print "\n****Frequent item sets calculation***\n"    candidate_dictionary = {}    with open(input_file) as file:        for transaction in file:            list_transaction = transaction.strip().split(',')            list_transaction = list(map(int, list_transaction))            list_transaction.sort()            #print "line being processed: ",            subset_k = itertools.combinations(list_transaction,2)            subset_k_list = list(subset_k)            for each_subset in subset_k_list:                if each_subset in candidate_item_sets:                    candidate_dictionary.setdefault(each_subset, 0)                    count = candidate_dictionary.get(each_subset)                    count += 1                    #print each_subset, " is now appearing for the ", count, " time"                    candidate_dictionary[each_subset] = count        frequent_item_list = []        for candidate_set, count in candidate_dictionary.iteritems():            if count >= support:                if candidate_item_set not in frequent_item_list:                    frequent_item_list.append(list(candidate_set))    file.close()    frequent_item_list.sort()    return frequent_item_listdef compute_candidate_item_sets(input_file, bit_map):    candidate_item_set = []    with open(input_file) as file:        for transaction in file:            list_transaction = transaction.strip().split(',')            list_transaction = list(map(int, list_transaction))            list_transaction.sort()            subset_k = itertools.combinations(list_transaction,2)            subset_k_list = list(subset_k)            #print "subsets of the above line: ", subset_k_list            for each_subset in subset_k_list:                subset_k_1_list = list(itertools.combinations(each_subset,1))                #print "subsets of k-1 length: ", subset_k_1_list                flag = 1                for item in subset_k_1_list:                    length = len(item)                    if(1 == length):                        for i in range(length):                            if item[i] not in frequent_item_list:                                flag = 0                    else:                        if list(item) not in frequent_item_list:                            flag = 0                if flag == 1:                    bucket_number = generate_hash_value(a,b,each_subset)                    if(1 == bit_map[bucket_number]):                        if each_subset not in candidate_item_set:                            candidate_item_set.append(each_subset)    file.close()    return candidate_item_setif __name__ == '__main__':        input_file = sys.argv[1]        a = sys.argv[2]        b = sys.argv[3]        support = sys.argv[4]        bucket_size = sys.argv[5]        foldername=sys.argv[6]        a=int(a)        b=int(b)        support = int(support)        bucket_size = int(bucket_size)        path= foldername        #print foldername        if not os.path.exists(path):            os.makedirs(path)        file = open(input_file,'r')        for transaction in file:            transaction = transaction.strip().split(',')            transaction = list(map(int, transaction))            for each_basket in transaction:                singleton_set.setdefault(each_basket, 0)                count = singleton_set.get(each_basket)                count += 1                singleton_set[each_basket] = count            singleton_dict=singleton_set        for item, count in singleton_dict.iteritems():            if count >= support:                frequent_item_list.append(int(item))        #print frequent_item_list        frequent_item_list.sort()        frq_sets_all.append(frequent_item_list)        file.close()        #print frq_sets_all        #compute_frequent_singleton_set(input_file)        while 0 != len(frequent_item_list):            hash_bucket = {}            for i in range(bucket_size):                hash_bucket[i] = 0            bit_map = [0]            #print "Hash bucket after initializing to 0: ", hash_bucket            bit_map,hash_bucket= compute_hash(bit_map,hash_bucket,input_file)            #print bit_map            #            # print hash_bucket            candidate_item_set = compute_candidate_item_sets(input_file, bit_map)            print len(candidate_item_set)            frequent_item_list = compute_frequent_item_sets(input_file, candidate_item_set)            frq_sets_all.append(frequent_item_list)            print frq_sets_all            # filename2 = 'Candidate_pairs.txt'            # cand_file= open(os.path.join(path, filename2), "w")            # for items in candidate_item_set:            #     cand_file.write(str(items)+'\n')            # cand_file.close()            print len(candidate_item_set)            filename1 = 'frequent_items.txt'            frq_file = open(os.path.join(path, filename1), "w")            for pairs in frq_sets_all:                for all in pairs:                    frq_file.write(str(all))                    frq_file.write('\n')            frq_file.close()            # #finding the FPR            # num_of_frequent_buckets=            # total_num_of_buckets= bucket_size            # FPR =0            # FPR= num_of_frequent_buckets/total_num_of_buckets